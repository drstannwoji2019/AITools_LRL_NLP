{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5b02ew5TZMuDBSFqhMERU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drstannwoji2019/AITools_LRL_NLP/blob/main/NLP_Text_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8P3lXVAQXF1",
        "outputId": "9c36af8d-36f2-4829-ff3c-c214096bbef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "%pip install -q spacy textblob nltk\n",
        "!python -m textblob.download_corpora\n",
        "!python -m spacy download en_core_web_sm\n",
        "import nltk # type: ignore\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample raw text\n",
        "text = \"OMG!! Dr. Smith prescribed 2 meds on Oct. 5, 2023. Can't believe it üò≤\"\n",
        "print(\"Original Text:\\n\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlKD-_ofQ11Q",
        "outputId": "394364e3-b7b2-4bcf-8844-ccc6a3c0919b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " OMG!! Dr. Smith prescribed 2 meds on Oct. 5, 2023. Can't believe it üò≤\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Lowercasing\n",
        "from nltk.tokenize import word_tokenize # type: ignore\n",
        "tokens = word_tokenize(text)\n",
        "tokens_lower = [t.lower() for t in tokens]\n",
        "print(\"Tokens (lowercase):\", tokens_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBD2Sj9uQ_KC",
        "outputId": "c6fd1258-4612-4d19-9489-575ffeb9696d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens (lowercase): ['omg', '!', '!', 'dr.', 'smith', 'prescribed', '2', 'meds', 'on', 'oct.', '5', ',', '2023', '.', 'ca', \"n't\", 'believe', 'it', 'üò≤']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopword Removal\n",
        "from nltk.corpus import stopwords # type: ignore\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [t for t in tokens_lower if t.isalpha() and t not in stop_words]\n",
        "print(\"Without Stopwords:\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm7nyc1zRKZS",
        "outputId": "a998c45b-86c8-4f1a-b0e1-c6fc8c421148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Stopwords: ['omg', 'smith', 'prescribed', 'meds', 'ca', 'believe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "from nltk.stem import PorterStemmer # type: ignore\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "print(\"Stemmed Words:\", stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIW7DPr5Rd61",
        "outputId": "db980381-75e6-4048-d7c2-4f252be538c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words: ['omg', 'smith', 'prescrib', 'med', 'ca', 'believ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "import spacy # type: ignore\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\" \".join(filtered_tokens))\n",
        "lemmas = [token.lemma_ for token in doc]\n",
        "print(\"Lemmatized Words:\", lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjYLs7cMR2do",
        "outputId": "57c06e89-3480-408c-d33f-97e53181a400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words: ['omg', 'smith', 'prescribe', 'med', 'can', 'believe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Numbers and Punctuation\n",
        "import re\n",
        "clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation\n",
        "print(\"Cleaned Text (no punctuation):\", clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu7PpIeoR4fl",
        "outputId": "569c0b87-481f-493c-9e04-27cbb20bdec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text (no punctuation): OMG Dr Smith prescribed 2 meds on Oct 5 2023 Cant believe it \n"
          ]
        }
      ]
    }
  ]
}